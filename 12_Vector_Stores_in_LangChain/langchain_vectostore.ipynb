{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ac8dd2e",
   "metadata": {},
   "source": [
    "# Chroma Vector Store using LangChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1099efa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eba7cb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={}, page_content='My name is Hasnain Yaqub. I am a beginner data scientist and GenAI learner from Pakistan.'), Document(metadata={}, page_content=\"I am currently learning Data Science and Artificial Intelligence through Codanics.com's 6 Months\"), Document(metadata={}, page_content='6 Months Data Science and AI Mentorship Program. My teacher and the founder of Codanics is Dr. The'), Document(metadata={}, page_content='is Dr. The program covers Statistics, Mathematics, Python, Pandas, NumPy, Scikit-learn, PyTorch,'), Document(metadata={}, page_content='PyTorch, SQL, Data Visualization, Machine Learning, Deep Learning, Generative AI, NLP, Prompt'), Document(metadata={}, page_content='NLP, Prompt Engineering, Time Series Analysis, Streamlit, Flask, FastAPI, Tableau, and Power BI.'), Document(metadata={}, page_content='My core strength is data analysis. I am skilled in Exploratory Data Analysis, data preprocessing,'), Document(metadata={}, page_content='preprocessing, data cleaning, data wrangling, feature understanding, and visualization using Python'), Document(metadata={}, page_content='using Python libraries.'), Document(metadata={}, page_content='I have completed multiple EDA projects including analysis of Google Play Store data, car dataset'), Document(metadata={}, page_content='car dataset analysis with preprocessing and column correction, and e-commerce data analysis. These'), Document(metadata={}, page_content='These projects are showcased on my portfolio website.'), Document(metadata={}, page_content='I am actively learning Generative AI and LangChain. I have worked with prompts, output parsers,'), Document(metadata={}, page_content='parsers, structured output, runnables, chains, and retrievers. I have built RAG based chatbots'), Document(metadata={}, page_content='based chatbots including a university information chatbot and a research paper explainer app using'), Document(metadata={}, page_content='app using Streamlit.'), Document(metadata={}, page_content='I have experience using Hugging Face models, OpenRouter models, Groq LLMs, and transformer based'), Document(metadata={}, page_content='based embeddings. I understand text embeddings, semantic search, vector stores, and retrieval'), Document(metadata={}, page_content='and retrieval pipelines.'), Document(metadata={}, page_content='I use Python as my primary programming language. I work in Linux environments and manage virtual'), Document(metadata={}, page_content='manage virtual environments using Conda. I have experience resolving dependency issues related to'), Document(metadata={}, page_content='related to NumPy, SciPy, Gensim, and transformer libraries.'), Document(metadata={}, page_content='I have basic backend knowledge using FastAPI. I understand HTTP methods, path and query parameters,'), Document(metadata={}, page_content='parameters, Pydantic models, POST, PUT, and DELETE requests. I have worked on backend features such'), Document(metadata={}, page_content='features such as user reviews storage using SQLite and API driven dashboards.'), Document(metadata={}, page_content='I am building my freelancing profiles on Fiverr and Upwork. I offer services related to data'), Document(metadata={}, page_content='to data analysis, machine learning, deep learning, NLP, and AI based solutions. I also provide'), Document(metadata={}, page_content='I also provide custom AI services.'), Document(metadata={}, page_content='My long term goal is to grow as an AI and ML engineer with a strong focus on Generative AI, RAG'), Document(metadata={}, page_content='AI, RAG systems, and applied AI products.')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "text = \"\"\"\n",
    "My name is Hasnain Yaqub. I am a beginner data scientist and GenAI learner from Pakistan.\n",
    "\n",
    "I am currently learning Data Science and Artificial Intelligence through Codanics.com's 6 Months Data Science and AI Mentorship Program. My teacher and the founder of Codanics is Dr. The program covers Statistics, Mathematics, Python, Pandas, NumPy, Scikit-learn, PyTorch, SQL, Data Visualization, Machine Learning, Deep Learning, Generative AI, NLP, Prompt Engineering, Time Series Analysis, Streamlit, Flask, FastAPI, Tableau, and Power BI.\n",
    "\n",
    "My core strength is data analysis. I am skilled in Exploratory Data Analysis, data preprocessing, data cleaning, data wrangling, feature understanding, and visualization using Python libraries.\n",
    "\n",
    "I have completed multiple EDA projects including analysis of Google Play Store data, car dataset analysis with preprocessing and column correction, and e-commerce data analysis. These projects are showcased on my portfolio website.\n",
    "\n",
    "I am actively learning Generative AI and LangChain. I have worked with prompts, output parsers, structured output, runnables, chains, and retrievers. I have built RAG based chatbots including a university information chatbot and a research paper explainer app using Streamlit.\n",
    "\n",
    "I have experience using Hugging Face models, OpenRouter models, Groq LLMs, and transformer based embeddings. I understand text embeddings, semantic search, vector stores, and retrieval pipelines.\n",
    "\n",
    "I use Python as my primary programming language. I work in Linux environments and manage virtual environments using Conda. I have experience resolving dependency issues related to NumPy, SciPy, Gensim, and transformer libraries.\n",
    "\n",
    "I have basic backend knowledge using FastAPI. I understand HTTP methods, path and query parameters, Pydantic models, POST, PUT, and DELETE requests. I have worked on backend features such as user reviews storage using SQLite and API driven dashboards.\n",
    "\n",
    "I am building my freelancing profiles on Fiverr and Upwork. I offer services related to data analysis, machine learning, deep learning, NLP, and AI based solutions. I also provide custom AI services.\n",
    "\n",
    "My long term goal is to grow as an AI and ML engineer with a strong focus on Generative AI, RAG systems, and applied AI products.\n",
    "\"\"\"\n",
    "\n",
    "spliter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=15\n",
    ")\n",
    "\n",
    "docs = spliter.split_text(\n",
    "    text\n",
    ")\n",
    "docs = [Document(page_content=chunk) for chunk in docs]\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e2400f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "emb = HuggingFaceEmbeddings(\n",
    "    model_name=\"nomic-ai/nomic-embed-text-v1\",\n",
    "    model_kwargs={\n",
    "        \"device\": \"cpu\",              # use \"cpu\" if no GPU\n",
    "        \"trust_remote_code\": True\n",
    "    },\n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f33e2d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add documents\n",
    "vector_store = FAISS.from_documents(docs, emb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7864edd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x73fee0359820>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd4b2a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(id='ac30a5b8-f8c7-49ee-92b1-9d581f40835c', metadata={}, page_content='to data analysis, machine learning, deep learning, NLP, and AI based solutions. I also provide'),\n",
       "  np.float32(0.5497476)),\n",
       " (Document(id='b4f2f88b-4c37-4275-9982-e71ba4bb84cf', metadata={}, page_content='PyTorch, SQL, Data Visualization, Machine Learning, Deep Learning, Generative AI, NLP, Prompt'),\n",
       "  np.float32(0.70201373))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search with similarity score\n",
    "vector_store.similarity_search_with_score(\n",
    "    query='machine learning and deep learning',\n",
    "    k=2\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
